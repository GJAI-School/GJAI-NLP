{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['#명령은 아래와 같이 반포되었다.\\n', '#명령은 반드시 엄격히 준수해야 한다.\\n', '#운명의 여신은 용사를 특별히 애호하신다.\\n']\n",
      "['#The order went forth that...\\n', '#The orders must be strictly obeyed.\\n', '#fortune favors the brave .\\n']\n",
      "                              kor                                            eng\n",
      "0            #명령은 아래와 같이 반포되었다.\\n                #The order went forth that...\\n\n",
      "1         #명령은 반드시 엄격히 준수해야 한다.\\n         #The orders must be strictly obeyed.\\n\n",
      "2       #운명의 여신은 용사를 특별히 애호하신다.\\n                  #fortune favors the brave .\\n\n",
      "3         #운명에 그가 죽을 것이라고 정해졌다.\\n            #Fate destined that he shall die.\\n\n",
      "4      #운명에 그는 목사가 될 것이라고 정해졌다.\\n         #Fate had ordained him to die young.\\n\n",
      "...                           ...                                            ...\n",
      "47662               #사자는 야생동물이다\\n                  #The lion is a wild animal.\\n\n",
      "47663            #사자는 황야로 도망갔다.\\n  #The lion escaped and returned to the wild.\\n\n",
      "47664   #사자는 우리 안에서 천천히 왔다갔다한다.\\n       #The lion paced the floor of its cage.\\n\n",
      "47665   #젖은 셔츠가 그의 몸에 착 달라붙어있다.\\n            #The wet shirt clung to his body.\\n\n",
      "47666      #젖은 성냥은 그어도 켜지지 않는다.\\n                  #Damp matches won't strike.\\n\n",
      "\n",
      "[47667 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "files = open(\"./data/par_corp.csv\" , encoding='utf-8')\n",
    "\n",
    "re_lines = []\n",
    "for line in files:\n",
    "    if line[0] == '[':\n",
    "        continue\n",
    "    re_line = re.sub('{#\".?!\\n}','', line)\n",
    "    re_lines.append(re_line)\n",
    "    \n",
    "kor = []\n",
    "eng = []\n",
    "count = 0\n",
    "for line in re_lines:\n",
    "    count = count + 1\n",
    "    if count % 2 == 0:\n",
    "        kor.append(line)\n",
    "    else:\n",
    "        eng.append(line)\n",
    "\n",
    "print(kor[:3])\n",
    "print(eng[:3])\n",
    "\n",
    "d = {'kor' : kor, 'eng' : eng}\n",
    "par_corp = pd.DataFrame(d)\n",
    "print(par_corp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder_input, decoder_input, decoder_output = [], [], []\n",
    "\n",
    "for stc in par_corp['kor']:\n",
    "    encoder_input.append(stc.split())\n",
    "\n",
    "# start뒤에 띄어쓰기 조심\n",
    "for stc in par_corp['eng']:\n",
    "    decoder_input.append((\"<start> \"+stc).split())\n",
    "\n",
    "# end앞에 띄어쓰기 조심\n",
    "for stc in par_corp['eng']:\n",
    "    decoder_output.append((stc+\" <end>\").split())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['#명령은', '아래와', '같이', '반포되었다.'], ['#명령은', '반드시', '엄격히', '준수해야', '한다.'], ['#운명의', '여신은', '용사를', '특별히', '애호하신다.']]\n",
      "[['<start>', '#The', 'order', 'went', 'forth', 'that...'], ['<start>', '#The', 'orders', 'must', 'be', 'strictly', 'obeyed.'], ['<start>', '#fortune', 'favors', 'the', 'brave', '.']]\n",
      "[['#The', 'order', 'went', 'forth', 'that...', '<end>'], ['#The', 'orders', 'must', 'be', 'strictly', 'obeyed.', '<end>'], ['#fortune', 'favors', 'the', 'brave', '.', '<end>']]\n"
     ]
    }
   ],
   "source": [
    "print(encoder_input[:3])\n",
    "print(decoder_input[:3])\n",
    "print(decoder_output[:3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer_ko = Tokenizer()\n",
    "tokenizer_ko.fit_on_texts(encoder_input)\n",
    "encoder_input = tokenizer_ko.texts_to_sequences(encoder_input)\n",
    "\n",
    "# 1~4999 까지만 인덱싱 변환\n",
    "tokenizer_en = Tokenizer(5000)\n",
    "tokenizer_en.fit_on_texts(decoder_input)\n",
    "tokenizer_en.fit_on_texts(decoder_output)\n",
    "decoder_input = tokenizer_en.texts_to_sequences(decoder_input)\n",
    "decoder_output = tokenizer_en.texts_to_sequences(decoder_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[14650, 1198, 331, 24225], [14650, 66, 7990, 6473, 12], [10413, 24226, 24227, 1199, 24228]]\n",
      "[[1, 5, 216, 94, 682, 1739], [1, 5, 1062, 75, 27, 2270, 16218], [1, 5746, 8301, 3, 4460, 53]]\n",
      "[[5, 216, 94, 682, 1739, 2], [5, 1062, 75, 27, 2270, 16218, 2], [5746, 8301, 3, 4460, 53, 2]]\n"
     ]
    }
   ],
   "source": [
    "print(encoder_input[:3])\n",
    "print(decoder_input[:3])\n",
    "print(decoder_output[:3])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 평균길이로 하면 번역과정에서 문장이 짤릴 위험이 있다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "len_ko = []\n",
    "for data in encoder_input:\n",
    "    len_ko.append(len(data))\n",
    "    \n",
    "len_en = []\n",
    "for data in decoder_input:\n",
    "    len_en.append(len(data))\n",
    "    \n",
    "plt.hist(len_ko, label='ko', alpha=0.5)\n",
    "plt.hist(len_en, label='en', alpha=0.5)\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 패딩할 때 순서가 중요하기 때문에\n",
    "#### max_len을 명시를 하지 않는 이유는 알아서 맞춰주기 떄문에"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder_input = pad_sequences(encoder_input, padding='post')\n",
    "decoder_input = pad_sequences(decoder_input, padding='post')\n",
    "decoder_output = pad_sequences(decoder_output, padding='post')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(47667, 27)\n",
      "(47667, 27)\n"
     ]
    }
   ],
   "source": [
    "print(encoder_input.shape)\n",
    "print(decoder_input.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 예측할 때 사용할꺼다. 카테고리 분류 때처럼 인덱스로 해당 카테고리/단어를 찾기 위함"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "en_to_index = tokenizer_en.word_index\n",
    "index_to_en = tokenizer_en.index_word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_size = 12000\n",
    "encoder_input_train = encoder_input[:-test_size]\n",
    "decoder_input_train = decoder_input[:-test_size]\n",
    "decoder_output_train = decoder_output[:-test_size]\n",
    "\n",
    "encoder_input_test = encoder_input[-test_size:]\n",
    "decoder_input_test = decoder_input[-test_size:]\n",
    "decoder_output_test = decoder_output[-test_size:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(35667, 27)\n",
      "(35667, 27)\n",
      "(35667, 27)\n",
      "(12000, 27)\n",
      "(12000, 27)\n",
      "(12000, 27)\n"
     ]
    }
   ],
   "source": [
    "print(encoder_input_train.shape)\n",
    "print(decoder_input_train.shape)\n",
    "print(decoder_output_train.shape)\n",
    "\n",
    "print(encoder_input_test.shape)\n",
    "print(decoder_input_test.shape)\n",
    "print(decoder_output_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Input, LSTM, Embedding, Dense, Masking\n",
    "from tensorflow.keras.models import Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 문장 길이만 넣고 데이터갯수는 넣지 않을까?\n",
    "# test데이터를 위해서 model.fit => validation_data \n",
    "encoder_inputs = Input(shape=(27, ))\n",
    "\n",
    "# len(tokenizer_ko.word_index)+1 : 몇개의 임베딩 벡터를 만들지, 뒤에 50은 하이퍼파라미터로 임의로 설정, \n",
    "# 패딩때문에, 패딩을 하고나면 0이붙기 때문에 1~4999 단어들이 있고 이후 0이라는 정수값도 포함이 되므로 \n",
    "encoder_embed = Embedding(len(tokenizer_ko.word_index)+1, 50)(encoder_input)\n",
    "\n",
    "# 0 (패딩) 같은 임베딩 벡터에서 제외시키겠다.\n",
    "encoder_mask = Masking(mask_value=0)(encoder_embed)\n",
    "\n",
    "# 50은 출력차원 \n",
    "encoder_outputs, h_state, c_state = LSTM(50, return_state=True)(encoder_mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "InvalidArgumentError",
     "evalue": "indices[19211,6] = 38984 is not in [0, 38984) [Op:ResourceGather] name: embedding_1/embedding_lookup/",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-36-56d55aafd2c6>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mdecoder_inputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mInput\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m27\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mdecoder_embed\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mEmbedding\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtokenizer_en\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mword_index\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m50\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mencoder_input\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[0mdecoder_mask\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mMasking\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmask_value\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdecoder_embed\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mdecoder_lstm\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mLSTM\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m50\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreturn_sequences\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreturn_state\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow_core\\python\\keras\\engine\\base_layer.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, inputs, *args, **kwargs)\u001b[0m\n\u001b[0;32m    889\u001b[0m           with base_layer_utils.autocast_context_manager(\n\u001b[0;32m    890\u001b[0m               self._compute_dtype):\n\u001b[1;32m--> 891\u001b[1;33m             \u001b[0moutputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcall\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcast_inputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    892\u001b[0m           \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_handle_activity_regularization\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moutputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    893\u001b[0m           \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_set_mask_metadata\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moutputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput_masks\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow_core\\python\\keras\\layers\\embeddings.py\u001b[0m in \u001b[0;36mcall\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m    181\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mdtype\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[1;34m'int32'\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mdtype\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[1;34m'int64'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    182\u001b[0m       \u001b[0minputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmath_ops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcast\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'int32'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 183\u001b[1;33m     \u001b[0mout\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0membedding_ops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0membedding_lookup\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0membeddings\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    184\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mout\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    185\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow_core\\python\\ops\\embedding_ops.py\u001b[0m in \u001b[0;36membedding_lookup\u001b[1;34m(params, ids, partition_strategy, name, validate_indices, max_norm)\u001b[0m\n\u001b[0;32m    315\u001b[0m       \u001b[0mname\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    316\u001b[0m       \u001b[0mmax_norm\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmax_norm\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 317\u001b[1;33m       transform_fn=None)\n\u001b[0m\u001b[0;32m    318\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    319\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow_core\\python\\ops\\embedding_ops.py\u001b[0m in \u001b[0;36m_embedding_lookup_and_transform\u001b[1;34m(params, ids, partition_strategy, name, max_norm, transform_fn)\u001b[0m\n\u001b[0;32m    133\u001b[0m       \u001b[1;32mwith\u001b[0m \u001b[0mops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolocate_with\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mparams\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    134\u001b[0m         result = _clip(\n\u001b[1;32m--> 135\u001b[1;33m             array_ops.gather(params[0], ids, name=name), ids, max_norm)\n\u001b[0m\u001b[0;32m    136\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mtransform_fn\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    137\u001b[0m           \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtransform_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow_core\\python\\util\\dispatch.py\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    178\u001b[0m     \u001b[1;34m\"\"\"Call target, and fall back on dispatchers if there is a TypeError.\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    179\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 180\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mtarget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    181\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mTypeError\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    182\u001b[0m       \u001b[1;31m# Note: convert_to_eager_tensor currently raises a ValueError, not a\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow_core\\python\\ops\\array_ops.py\u001b[0m in \u001b[0;36mgather\u001b[1;34m(***failed resolving arguments***)\u001b[0m\n\u001b[0;32m   3963\u001b[0m     \u001b[1;31m# TODO(apassos) find a less bad way of detecting resource variables without\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3964\u001b[0m     \u001b[1;31m# introducing a circular dependency.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3965\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mparams\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msparse_read\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mindices\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3966\u001b[0m   \u001b[1;32mexcept\u001b[0m \u001b[0mAttributeError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3967\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mgen_array_ops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgather_v2\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mparams\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindices\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow_core\\python\\ops\\resource_variable_ops.py\u001b[0m in \u001b[0;36msparse_read\u001b[1;34m(self, indices, name)\u001b[0m\n\u001b[0;32m    638\u001b[0m       \u001b[0mvariable_accessed\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    639\u001b[0m       value = gen_resource_variable_ops.resource_gather(\n\u001b[1;32m--> 640\u001b[1;33m           self._handle, indices, dtype=self._dtype, name=name)\n\u001b[0m\u001b[0;32m    641\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    642\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_dtype\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0mdtypes\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvariant\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow_core\\python\\ops\\gen_resource_variable_ops.py\u001b[0m in \u001b[0;36mresource_gather\u001b[1;34m(resource, indices, dtype, batch_dims, validate_indices, name)\u001b[0m\n\u001b[0;32m    667\u001b[0m       \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    668\u001b[0m         \u001b[0mmessage\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 669\u001b[1;33m       \u001b[0m_six\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mraise_from\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_core\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_status_to_exception\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcode\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    670\u001b[0m   \u001b[1;31m# Add nodes to the TensorFlow graph.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    671\u001b[0m   \u001b[0mdtype\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_execute\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmake_type\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"dtype\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\six.py\u001b[0m in \u001b[0;36mraise_from\u001b[1;34m(value, from_value)\u001b[0m\n",
      "\u001b[1;31mInvalidArgumentError\u001b[0m: indices[19211,6] = 38984 is not in [0, 38984) [Op:ResourceGather] name: embedding_1/embedding_lookup/"
     ]
    }
   ],
   "source": [
    "decoder_inputs = Input(shape=(27,))\n",
    "decoder_embed = Embedding(len(tokenizer_en.word_index)+1, 50)(encoder_input)\n",
    "decoder_mask = Masking(mask_value=0)(decoder_embed)\n",
    "\n",
    "decoder_lstm = LSTM(50, return_sequences=True, return_state=True)\n",
    "decoder_output,_ ,_ = decider_lstm(decoder_mask, initial_state=[h_state, c_state])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
